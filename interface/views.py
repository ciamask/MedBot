# -*- coding: utf-8 -*-

from django.http import HttpResponse
from django.shortcuts import render
from django.http import JsonResponse
import json
import urllib, json



def exe(request):
    Data=request.GET.get('msg')
    import numpy as np
    import matplotlib.pyplot as plt
    import pandas as pd
    import re
    import nltk
    import csv
    from sklearn.ensemble import RandomForestClassifier
    from nltk import word_tokenize
    # nltk.download('stopwords')
    from nltk.corpus import stopwords
    from fuzzywuzzy import fuzz
    #nltk.download('averaged_perceptron_tagger')
    #nltk.download('punkt')
    #from nltk.stem.porter import PorterStemmer

    # Importing the dataset
    dataset_train = pd.read_csv('../Training.csv')
    X_train= dataset_train.iloc[:, :-1].values
    y_train = dataset_train.iloc[:, -1].values
    dy = pd.DataFrame(y_train)

    #identifying column header
    fieldnames=[]
    symptoms_column_dict={}
    i=0
    for col in dataset_train.columns:
        fieldnames.append(col)
    symptoms={}
    #now for each symptoms given remove anything other than a string and give a column number for update
    for s in fieldnames:
        symptoms.update( {s : 0} )
        s=re.sub('[^a-zA-Z]', ' ',s)
        s=s.lower()
        symptoms_column_dict.update( {s : i} )
        i+=1


    #Cleaning
    #obtain user input ,tokenize and find parts of speech
    entered_symptoms=Data
    def clean_ner(entered_symptoms):
        entered_symptoms=re.sub('[^a-zA-Z]', ' ',entered_symptoms)
        entered_symptoms=entered_symptoms.lower()
        tokenized_symptoms = word_tokenize(entered_symptoms)
        pos_inp_sentence=nltk.pos_tag(tokenized_symptoms)
        #combine the words to form a string using pattern via ner
        pattern = 'NP: {(<NN|VBG>?<NNS>*<IN>*<NN|NNS|VBD|RB>)?(<JJ|VBN|RB>?<NN>*<VBG|VBP|NN|VBN|NNS>)?}'
        cp = nltk.RegexpParser(pattern)
        return cp.parse(pos_inp_sentence)

    #convert the tree of possible symptoms generated by ner to string and store in list
    def possibleSymptoms(symptom_combinations):
        user_symptoms=[]
        true=0
        for l in symptom_combinations:
            true=0
            tree_to_string=""
            for i in l:
               if(i[0] not in stopwords.words('english')):
                   if(i[1]=='NN' or i[1]=='NNS' or i[1]=='JJ' or i[1]=='VBG' or i[1]=='VBN' or i[1]=='RB' or i[1]=='VBD'):
                       tree_to_string=tree_to_string+' '+i[0]
                       true=1
            if(true==1):
                 user_symptoms.append(tree_to_string)
        return user_symptoms;


    #compare the symptoms with symptoms available and return true if its matching
    list_symp=[0] * 132
    def compareWithProvidedSymptoms(user_symptoms):
        symexist=0
        rat=0
        for l in user_symptoms:
            for sy,v in symptoms_column_dict.items():
                rat=0
                rat=fuzz.token_set_ratio(l,sy)
                if(rat>78 ):
                    print(sy)
                    list_symp[v]=1
                    symexist=1
        return symexist

    symptom_combinations = clean_ner(entered_symptoms)
    user_symptoms=possibleSymptoms(symptom_combinations)
    symexist=compareWithProvidedSymptoms(user_symptoms)

    if symexist==1:
        #fitting random for classifcation to training set
        classifier=RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)
        classifier.fit(X_train,y_train)
        RandomForestClassifier()

    responseData = "I have understood that you have following symptoms: "+" ".join([token for token in user_symptoms])
    return JsonResponse({'message':responseData, 'disease':classifier.predict([list_symp])[0]})
